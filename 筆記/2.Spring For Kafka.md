####建立Topic
```java
@Configuration
public class KafkaConfig {
	
	@Value("${spring.kafka.bootstrap-servers}")
	private String kafkaServers;

	@Bean
	public KafkaAdmin admin() {
		Map<String, Object> configs = new HashMap<>();
		// 建立到Kafka cluster的"初始"連接主機。無論設置為何，客戶端都會使用所有的server
		configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServers);
		return new KafkaAdmin(configs);
	}
	
	/**
	 * 如果Topic不存在就建立
	 * @param topicName
	 * @return
	 */
	@Bean
	public NewTopic myTopic(@Value("${spring.kafka.topic-name}") String topicName) {
		return TopicBuilder.name(topicName)
				.partitions(3)
				.replicas(2)
				.build();
	}
}
```
#####查看Topic狀態
```batch
> .\bin\windows\kafka-topics.bat --describe --bootstrap-server localhost:9092 --topic myTopic
Topic: myTopic  PartitionCount: 3       ReplicationFactor: 2    Configs: segment.bytes=1073741824
        Topic: myTopic  Partition: 0    Leader: 2       Replicas: 2,1   Isr: 2,1
        Topic: myTopic  Partition: 1    Leader: 1       Replicas: 1,0   Isr: 1,0
        Topic: myTopic  Partition: 2    Leader: 0       Replicas: 0,2   Isr: 0,2
```
* Leader：負責Partition的所有讀寫。以Partition 0為例，它的Leader是位在broker 2。
* Replicas：2,1表示它的副本位在broker 2和broker 1。
* Isr (In-sync replica)：已同步的副本。若將broker 1關掉以模擬broker 1斷線，則
    ```batch
    Topic: myTopic  PartitionCount: 3       ReplicationFactor: 2    Configs: segment.bytes=1073741824
        Topic: myTopic  Partition: 0    Leader: 2       Replicas: 2,1   Isr: 2
        Topic: myTopic  Partition: 1    Leader: 0       Replicas: 1,0   Isr: 0
        Topic: myTopic  Partition: 2    Leader: 2       Replicas: 0,2   Isr: 2,0
    ```
<br>

####Producer
透過KafkaTemplate發送訊息。
```java
@Configuration
public class KafkaProducerConfig {
	
	@Value("${spring.kafka.bootstrap-servers}")
	private String kafkaServers;

	@Bean
	public KafkaTemplate<String, TestDto> kafkaTemplate() {
		return new KafkaTemplate<>(producerFactory());
	}
	
	@Bean
	public ProducerFactory<String, TestDto> producerFactory() {
		return new DefaultKafkaProducerFactory<>(producerConfigs());
	}
	
	@Bean
	public Map<String, Object> producerConfigs() {
		Map<String, Object> configs = new HashMap<>();
		configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServers);	
		configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
		configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
		return configs;
	}
}
```
<br>

####Consumer
透過@KafkaListener接收訂閱Topic的訊息，需要有KafkaListenerContainerFactory。
```java
@Configuration
@EnableKafka
public class KafkaConsumerConfig {
	
	@Value("${spring.kafka.bootstrap-servers}")
	private String kafkaServers;
	
	@Bean
	public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, TestDto>> kafkaListenerContainerFactory() {
		ConcurrentKafkaListenerContainerFactory<String, TestDto> factory = new ConcurrentKafkaListenerContainerFactory<>();
		factory.setConsumerFactory(consumerFactory());
		/*
		 * 產生3個KafkaListenerContainer同時處理3個Partition
		 * 可在@KafkaListener覆蓋設定
		 */
		factory.setConcurrency(3);
		
		ContainerProperties props = factory.getContainerProperties();
		props.setPollTimeout(3000);
		props.setAckMode(AckMode.MANUAL_IMMEDIATE);		// 手動commit
		return factory;
	}

	@Bean
	public ConsumerFactory<String, TestDto> consumerFactory() {
//		return new DefaultKafkaConsumerFactory<>(consumerConfigs(), null, new JsonDeserializer<>(TestDto.class));
		return new DefaultKafkaConsumerFactory<>(consumerConfigs());
	}
	
	@Bean
	public Map<String, Object> consumerConfigs() {
		Map<String, Object> configs = new HashMap<>();
		configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServers);
		// 反序列化器要與Producer的序列化器成對
		configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
		// Consumer的JsonDeserializer要另外指定信任的package 或 在ConsumerFactory的建構子傳入JsonDeserializer的實例
		configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
		configs.put(JsonDeserializer.TRUSTED_PACKAGES, "yfu.practice.springkafka.dto");
		/*
		 * 當指定Topic沒有初始offset要如何重置
		 * earliest: 自動重置為最早的offset
		 * latest: 自動重置為最新的offset
		 * none: 在Consumer group中尋找前一個offset，若無拋例外
		 * anything else: 拋例外
		 */
		configs.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");	
		return configs;
	}
}
```
```java
@Component
public class Listener {

	@KafkaListener(topics = "${spring.kafka.topic-name}", groupId = "myListener",
			concurrency = "3",	// 可同時處理3個partition
			containerFactory = "kafkaListenerContainerFactory")	// containerFactory的beanName，預設值名稱是kafkaListenerContainerFactory
	public void myListener(TestDto testDto, Acknowledgment ack) {	// ActMode為手動commit時，可用Acknowledgment進行commit
		// do something when the listener gets messages
		ack.acknowledge();	// commit
	}
}
```